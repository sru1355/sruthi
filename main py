import os
import pdfplumber
import pytesseract
from PIL import Image
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from transformers import pipeline

# Step 1: Extract text from PDFs (including OCR for image-based text)
def extract_text_from_page(pdf_path, page_number):
    with pdfplumber.open(pdf_path) as pdf:
        if page_number <= len(pdf.pages):
            page = pdf.pages[page_number]
            if page.extract_text():
                return page.extract_text()
            else:
                # OCR if page contains images
                image = page.to_image().original
                image.save("temp_page.png")
                return pytesseract.image_to_string(Image.open("temp_page.png"))
        else:
            return f"Page {page_number} not found in PDF."

# Step 2: Extract tabular data
def extract_table_from_page(pdf_path, page_number):
    with pdfplumber.open(pdf_path) as pdf:
        if page_number <= len(pdf.pages):
            page = pdf.pages[page_number]
            return page.extract_table()
        else:
            return f"Page {page_number} not found in PDF."

# Step 3: Chunk text into smaller parts
def chunk_text(text, chunk_size=500):
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

# Step 4: Generate vector embeddings
def generate_embeddings(chunks):
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = [model.encode(chunk) for chunk in chunks]
    return model, embeddings

# Step 5: Create FAISS vector database
def create_faiss_index(embeddings):
    index = faiss.IndexFlatL2(embeddings[0].shape[0])
    index.add(np.array(embeddings))
    return index

# Step 6: Retrieve similar chunks
def retrieve_similar_chunks(query, index, chunks, model, top_k=3):
    query_embedding = model.encode(query)
    distances, indices = index.search(np.array([query_embedding]), top_k)
    return [chunks[idx] for idx in indices[0]]

# Step 7: Generate answers using LLM
def generate_response(query, context):
    qa_pipeline = pipeline("question-answering", model="distilbert-base-cased-distilled-squad")
    response = qa_pipeline(question=query, context=" ".join(context))
    return response['answer']

# Main function
def main():
    pdf_path = "pdf_data/sample.pdf"  # Replace with your PDF file
    page_2_text = extract_text_from_page(pdf_path, 2)  # Handles OCR if needed
    page_6_table = extract_table_from_page(pdf_path, 6)  # Extracts tabular data

    # Print extracted data
    print("Text from Page 2:\n", page_2_text)
    print("\nTable from Page 6:\n", page_6_table)

    # Process and retrieve specific information
    chunks = chunk_text(page_2_text)  # Chunk text from Page 2
    model, embeddings = generate_embeddings(chunks)  # Generate embeddings
    index = create_faiss_index(embeddings)  # Create FAISS index

    # Query and response generation
    query = "What is the unemployment rate for Bachelor's degree holders?"
    relevant_chunks = retrieve_similar_chunks(query, index, chunks, model)
    answer = generate_response(query, relevant_chunks)
    print("\nGenerated Answer:\n", answer)

if name == "main":
    main()
